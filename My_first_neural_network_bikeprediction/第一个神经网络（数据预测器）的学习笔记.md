

# 第一个神经网络复现的学习笔记



## 一. 人工神经网络简介

人工神经网络也被称为通用拟合器，这是因为他可以拟合任何的函数或映射。

前馈神经网络是我们常用的一种神经网络，一般包括3层，这里隐藏层可以有多层，这就构成了所谓的深度神经网络。（这里搭建最简单的3层神经网络，用来了解神经网络如何工作）

<img src="E:\typora-user-images\image-20200513195857290.png" alt="image-20200513195857290" style="zoom:50%;" />



### 1.1人工神经元（数学公式分析笔记本上）

单神经元模型：

<img src="E:\typora-user-images\image-20200513211540710.png" alt="image-20200513211540710" style="zoom:50%;" />

双神经元模型：

<img src="E:\typora-user-images\image-20200513214646952.png" alt="image-20200513214646952" style="zoom:50%;" />





利用两个神经元可以制造出一个波峰，这里引申出一个定理。

通用逼近原理（universal approximation theorem）：利用有限多的隐藏层神经元可以逼近任意的有限区间内的曲线。

## 二. 单车预测1.0

这里单车数据csv来源：（Capital Bikeshare） 

下载地址：https://www.capitalbikeshare.com/system-data 。

### 2.1 神经网络框架

以数据前50个为训练集，训练模型

![image-20200516220842584](E:\typora-user-images\image-20200516220842584.png)

```python
import numpy as np     #numpy库调取，numpy是用来存储和处理大型的矩阵
import pandas as pd    #pandas库调取，numpy基础上的衍生工具这里是用来读取csv文件
import torch           #pytorch框架
from torch.autograd import Variable     #调用框架内自动微分下变量工具（笔记详细解释）
import matplotlib.pyplot as plt         #绘图工具

data_path = 'luchen.csv'                #这里是调用csv文件，存储在变量data_path中
rides = pd.read_csv(data_path)          #这里是通过pandas中read_csv模块，读取数据
rides.head()                            #输出部分原始数据，pycharm上显示是5*9矩阵
counts = rides['Duration'][:50]         #截取数据，Duration列前50
x = np.arange(len(counts))              #x轴定义，arange(50)=array([0,1,2,3...50])
y = np.array(counts)                    #y轴定义，读取count内对应的时间,转变数组，并与x一一对应
plt.figure(figsize=(10, 7))             #设定绘图窗口大小
plt.plot(x, y, 'o-')                    #标出xy，‘o-’指的是用点描绘出来
plt.xlabel('X')                         #标签X轴
plt.ylabel('Y')                         #标签Y轴
plt.show()                              #显示图片
print(counts)                           #查看count输出，是什么形式
```

 



```python
counts = rides['cnt'][:50]
# torch.tensor()函数公式，输入变量，1，2，3...这样的一维数组
x = torch.tensor(np.arange(len(counts), dtype=float), requires_grad=True)
# 输出变量，它是从数据counts中读取的每一辆车的行驶时间，共50个数据点的一维数组，作为标准答案
y = torch.tensor(np.array(counts, dtype=float), requires_grad=True)

sz = 10  # 设置隐藏层的神经元的数量

# 初始化输入层到隐藏层的权重矩阵，它的尺寸是（1，10）
weights = torch.randn((1, sz), dtype=torch.double, requires_grad=True)  

# 初始化隐藏层节点的偏置向量，它是尺寸为10的一位向量
biases = torch.randn(sz, dtype=torch.double, requires_grad=True)  

# 初始化隐藏层到输出层的权重矩阵，它的尺寸是（10，1）
weights2 = torch.randn((sz, 1), dtype=torch.double, requires_grad=True) 

learning_rate = 0.0001                        # 学习率，针对权重w与变差b更新的步长
losses = []                                   # 空的数组，用来收录后面生成的数据
x = x.view(50,-1)                             # 展示成一维，即（50,10），便于与weights相乘
y = y.view(50,-1)                             # 同理
for i in range(1000000):                      # 迭代计算一百万次
    hidden = x * weights + biases             # 隐藏层计算
    hidden = torch.sigmoid(hidden)            # sigmoid函数
    predictions = hidden.mm(weights2)         # y的预测值，矩阵运算weights2,hidden
    
    # 损失函数计算，torch.mean(data,1(每行平均),dim=True使输出与输入有相同的维度)，这里loss求均方差
    loss = torch.mean((predictions - y) ** 2)
    
    #losses数组append添加元素，loss.data.numpy()转变numpy是一个数
    losses.append(loss.data.numpy())          
    if i % 10000 == 0:                        # 这里与10000相除取余数，是否等于0
        print('loss', loss)


# ***********************************************************************
    loss.backward()                           # 对损失函数进行梯度反传
# 利用上一步计算中得到的weights，biases等梯度信息更新weights以及biases的数值
    weights.data.add_(- learning_rate * weights.grad.data)
    biases.data.add_(- learning_rate * biases.grad.data)
    weights2.data.add_(- learning_rate * weights2.grad.data)

# 清空所有变量的梯度值
    weights.grad.data.zero_()
    biases.grad.data.zero_()
    weights2.grad.data.zero_()

plt.plot(losses)                               # plot()标点
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.show()

x_data = x.data.numpy()                        # 建立新变量x_date并获取x内数据,转变x为numpy数据
plt.figure(figsize=(10, 7))                    # 设定绘图窗口大小
xplot, = plt.plot(x_data, y.data.numpy(), 'o') # 绘制原始数据，指标点，不连接
yplot, = plt.plot(x_data, predictions.data.numpy())  # 绘制拟合数据，不标出，只连线
plt.xlabel('X')                                # 更改坐标轴标注
plt.ylabel('Y')                                # 更改坐标轴标注
plt.legend([xplot, yplot], ['Data', 'Prediction under 1000000 epochs'])  #图列说明
plt.show()

```

### 2.2 第一次Out输出

原始数据，标点 x y轴：

<img src="E:\typora-user-images\image-20200515105207933.png" alt="image-20200515105207933" style="zoom:50%;" />

1000000次迭代后，损失函数



<img src="E:\typora-user-images\image-20200515105314445.png" alt="image-20200515105314445" style="zoom: 67%;" />

预测点与原始数据拟合程度：

<img src="E:\typora-user-images\image-20200515173336644.png" alt="image-20200515173336644" style="zoom:50%;" />











### 2.3 改进输出

数据在 x=20 之后，几乎为直线，**过拟合**现象。归一化处理让数据处理更快，事实上有足够的时间一样也可以拟合好数据。这时对 x 进行归一化处理

`x = torch.tensor(np.arange(len(counts), dtype=float), requires_grad=True)`

<img src="E:\typora-user-images\image-20200516002336589.png" alt="image-20200516002336589" style="zoom:50%;" />



<img src="E:\typora-user-images\image-20200516002351235.png" alt="image-20200516002351235" style="zoom:33%;" />



这里数据后半段则明显转好，原因没明白？归一化处理，本意是使数据迭代速度加快，可以减轻过拟合现象？

### 2.4  测试集检验神经网络

测试集后50个数据

```python
counts_predict = rides['cnt'][50:100]   # 读取后50个数据
# 首先对接下来的50个数据点进行选取，注意x应该取51，52，……，100，然后再归一化
x = torch.tensor((np.arange(50, 100, dtype=float) / len(counts)), requires_grad=True)
# 读取下50个点的y数值，不需要做归一化
y = torch.tensor(np.array(counts_predict, dtype=float), requires_grad=True)

x = x.view(50, -1)
y = y.view(50, -1)

# 从输入层到隐含层的计算
hidden = x * weights + biases

# 将sigmoid函数作用在隐含层的每一个神经元上
hidden = torch.sigmoid(hidden)

# 隐含层输出到输出层，计算得到最终预测
predictions = hidden.mm(weights2)

# 计算预测数据上的损失函数
loss = torch.mean((predictions - y) ** 2)
print(loss)

x_data = x.data.numpy()                              # 获得x包裹的数据
plt.figure(figsize=(10, 7))                          # 设定绘图窗口大小
xplot, = plt.plot(x_data, y.data.numpy(), 'o')       # 绘制原始数据
yplot, = plt.plot(x_data, predictions.data.numpy())  # 绘制拟合数据
plt.xlabel('X')                                      # 更改坐标轴标注
plt.ylabel('Y')                                      # 更改坐标轴标注
plt.legend([xplot, yplot], ['Data', 'Prediction'])   # 绘制图例
plt.show()
```

### 2.5 测试集输出

<img src="E:\typora-user-images\image-20200516220228811.png" alt="image-20200516220228811" style="zoom:50%;" />

明显的过拟合现象，这里发生的原因是在于 x 轴的对象选取错误，错误的只是用序号1-50来代表使用当前车辆使用的情况，未考虑风速，节假日，星期几，天气等其他因素，所以这个是教训。

### 2.6 知识点汇总

#### 1.   关于8位，16位，32位、64位整型，浮点数概念

```python

import numpy as np
import sys

# 32位整型
ai32 = np.array([], dtype=np.int32)
bi32 = np.arange(1, dtype=np.int32)
ci32 = np.arange(5, dtype=np.int32)

# 64位整型
ai64 = np.array([], dtype=np.int64)
bi64 = np.arange(1, dtype=np.int64)
ci64 = np.arange(5, dtype=np.int64)

# 32位浮点数
af32 = np.array([], dtype=np.float32)
bf32 = np.arange(1, dtype=np.float32)
cf32 = np.arange(5, dtype=np.float32)

# 64位浮点数
af64 = np.array([], dtype=np.float64)
bf64 = np.arange(1, dtype=np.float64)
cf64 = np.arange(5, dtype=np.float64)

print("size of 0 int32 number: %f" % sys.getsizeof(ai32))
print("size of 1 int32 number: %f" % sys.getsizeof(bi32))
print("size of 5 int32 numbers: %f" % sys.getsizeof(ci32), end='\n\n')

print("size of 0 int64 number: %f" % sys.getsizeof(ai64))
print("size of 1 int64 number: %f" % sys.getsizeof(bi64))
print("size of 5 int64 numbers: %f" % sys.getsizeof(ci64), end='\n\n')

print("size of 0 float32 number: %f" % sys.getsizeof(af32))
print("size of 1 float32 number: %f" % sys.getsizeof(bf32))
print("size of 5 float32 numbers: %f" % sys.getsizeof(cf32), end='\n\n')

print("size of 0 float64 number: %f" % sys.getsizeof(af64))
print("size of 1 float64 number: %f" % sys.getsizeof(bf64))
print("size of 5 float64 numbers: %f" % sys.getsizeof(cf64))
```



out：

![image-20200515002751949](E:\typora-user-images\image-20200515002751949.png)



可以看出字节大小对应精度成正比，同时与内存占用率也成正比



#### 2.  关于`torch.tensor`与`torch.Tensor`之间的区别

![image-20200515002931957](E:\typora-user-images\image-20200515002931957.png)

这里`torch.tensor`是一个 `pytorch` 里一个函数，可以从原本data中将数据部分做拷贝，不影响原数据。

`tensor( data ,dtype =，device=GPU/CPU , requires_grad=Ture/False)`



而`torch.Tensor`是Python类，更明确的说，是默认张量类型`torch.FloatTensor`()的别名，会调用Tensor类的构造函数 `__init__` ，生成单精度浮点类型的张量(32位的单精度浮点类型张量)。



#### 3. 关于`torch.randn()`的定义

`torch.rand`和`torch.randn`有什么区别？

例如： `y = torch.rand(4,4) `与 `y=torch.randn(4,4)`前者是均匀分布（0，1），而后者是标准正态分布  

（均值为0，方差为1）





```python
a = torch.randn(4, 4)                # torch.randn(4,4) 生成（4，4）维的矩阵
b = torch.mean(a, 1, True)
print(a)
print(b)

biases = torch.randn(10, dtype = torch.double, requires_grad = True)
print(biases)
```

<img src="E:\typora-user-images\image-20200520173644945.png" alt="image-20200520173644945" style="zoom:67%;" />



## 三. 单车预测2.0

![image-20200516220906433](E:\typora-user-images\image-20200516220906433.png)

结合上面失败的神经网络，这里将不再单单只取1-50序列为x值。而是综合星期几、天气、湿度、温度等





### 3.1 对数据进行预处理

这里将变量分为两种类型：类型变量、数值变量。

类型变量：例如星期几（weekday）（一二三四五六日）、天气（“weathersit”）（1晴天、2多云、3小雨/雪、4大雨/雪）。



数值变量：湿度（humidity）（[0,1]区间可以连续取值），当然温度、风速也是这种类型的变量。



#### 1、对类型变量进行处理，dummies（one-hot）编码

```python
import numpy as np
import pandas as pd
import torch
import matplotlib.pyplot as plt

# ****************************************
# 先对数据进行预处理
data_path = 'hour.csv'                     # 找到读取的路径
rides = pd.read_csv(data_path)             # pandas工具依据路径读取数据
#路径文件中的“类”
dummy_fields = ['season', 'weathersit', 'mnth', 'hr', 'weekday']  
for each in dummy_fields:                  # 依次读取“类”中的数据，转变“one-hot”独热编码
    
    #pd.get_dummies(data,prefix(前缀)=(),drop_first(忽略首位))
    dummies = pd.get_dummies(rides[each], prefix=each, drop_first=False)
    
    #pd.concat()数据合并与重组，下面会解释
    rides = pd.concat([rides, dummies], axis=1)

fields_to_drop = ['instant', 'dteday', 'season', 'weathersit', 'weekday', 'atemp', 'mnth', 'workingday', 'hr']                                      # 选择“类”
data = rides.drop(fields_to_drop, axis=1)  # rides.drop()忽略选择“类”中的数据
print(data，end='\n\n')
```



![image-20200520022804116](E:\typora-user-images\image-20200520022804116.png)



#### 2、对数值变量进行处理，归一化处理。

```python
# 数值类型变量的处理，归一化
quant_features = ['cnt', 'temp', 'hum', 'windspeed']   # 需要归一化处理的数值型变量
scaled_features = {}                                   # 字典，储存每个变量的[均值，方差]
for each in quant_features:                            # 依次读取选择的“类”
    mean, std = data[each].mean(), data[each].std()    # 计算“类”的均值与方差
    scaled_features[each] = [mean, std]                # 将计算后的[均值，方差]存储到字典中
    data.loc[:, each] = (data[each] - mean) / std      # 归一化公式，使数值型变量区间[-1，1]
```



#### 3、设置训练集与测试集

```python
# 训练集，测试集
train_data = data[:-21 * 24]                           # 这里负号意思从右(数据最后)开始数起
test_data = data[-21 * 24:]                            


target_fields = ['cnt', 'casual', 'registered']        # 选择“类”，目标集
# 输出训练集的特征与目标
features, targets = train_data.drop(target_fields, axis=1), train_data[target_fields]
# 输出测试集的特征与目标
test_features, test_targets = test_data.drop(target_fields, axis=1),
test_data[target_fields]

print(features,end='\n\n')
print(targets,end='\n\n')
```

数据集示意图：

<img src="E:\typora-user-images\image-20200520025019439.png" alt="image-20200520025019439" style="zoom:50%;" />

训练集中特征数据集：

<img src="E:\typora-user-images\image-20200520030022061.png" alt="image-20200520030022061" style="zoom: 67%;" />

训练集中目标数据集：

<img src="E:\typora-user-images\image-20200520030720666.png" alt="image-20200520030720666" style="zoom:67%;" />









```python
# 将数据从pandas dataframe转换为numpy
X = features.values
print(X,end=('\n\n'))
print(len(X))
Y = targets['cnt'].values
Y = Y.astype(float)                          # 保证数据为实数
Y = np.reshape(Y, [len(Y), 1])               # 使Y数据变为（16875，1）维

```

X的数据结构:

<img src="E:\typora-user-images\image-20200520164254138.png" alt="image-20200520164254138" style="zoom:67%;" />

Y的数据结构:

<img src="E:\typora-user-images\image-20200520031214289.png" alt="image-20200520031214289" style="zoom:67%;" />



### 3.2 搭建神经网络框架并训练神经网络

使用两种方式编写神经网络框架。一是完整编写，二是直接调用pytorch内现成函数。

框架结构：

![image-20200522192404245](E:\typora-user-images\image-20200522192404245.png)

#### 1、常规手动编写完整版本（2.0版本）

```python
losses = []                     # 收录每次
input_size = features.shape[1]  # data.shape[0或1]，0是读行数，1是读列数。
hidden_size = 10                # 隐藏层数
output_size = 1                 # 输出层数
batch_size = 128                # 设立batch数，一撮数据，2^n。

# 权重与偏差
weights1 = torch.randn([input_size, hidden_size], dtype=torch.double, requires_grad=True)
biases1 = torch.randn([hidden_size], dtype=torch.double, requires_grad=True)
weights2 = torch.randn([hidden_size, output_size], dtype=torch.double, requires_grad=True)

# 定义各类函数
def neu(x):                      # 正向传播计算公式
    hidden = x.mm(weights1) + biases1.expand(x.size()[0], hidden_size)
    hidden = torch.sigmoid(hidden)
    output = hidden.mm(weights2)
    return output


def cost(x, y):                  # 成本函数计算公式
    error = torch.mean((x - y) ** 2)
    return error


def zero_grad():                 # 权重与偏差重置为0
    if weights1.grad is not None and biases1.grad is not None and weights2.grad is not None:
        weights1.grad.data.zero_()
        weights2.grad.data.zero_()
        biases1.grad.data.zero_()


def optimizer_step(learning_rate): # 反向传播计算公式
    weights1.data.add_(-learning_rate * weights1.grad.data)
    weights2.data.add(-learning_rate * weights2.grad.data)
    biases1.data.add(-learning_rate * biases1.grad.data)
    
# 神经网络循环

for i in range(1000):                           # 1000次迭代
    batch_loss = []                             # batch_loss
    # range(0,16875,128)，范围（0，16875），每次跳跃128
    for start in range(0, len(X), batch_size):  
        # 切分数据集
        end = start + batch_size if start + batch_size < len(X) else len(X)
        # xx,yy分别为特征变量的一批数据，目标变量的一批数据
        xx = torch.tensor(X[start:end], dtype=torch.double, requires_grad=True)
        yy = torch.tensor(Y[start:end], dtype=torch.double, requires_grad=True)
        prediction = neu(xx)                     # 计算正向传播的预测值
        loss = cost(prediction, yy)              # 计算成本函数
        zero_grad()                              # 先对权重以及偏差的求导值清零
        loss.backward()                          # 这时对成本函数求导，反向传播
        optimizer_step(0.01)                     # 设置学习率，更新权重与偏差
        batch_loss.append(loss.data.numpy())     # 一次迭代中，存储每一批数据的成本函数值

    if i % 100 == 0:                             # 计算余数
            # 每100次迭代后，计算batch均值，并添加至losses数列中
            losses.append(np.mean(batch_loss))   
            print(i, np.mean(batch_loss))
            
fig = plt.figure(figsize=(10, 7))
# 这里len(losses)计算，由于每100迭代输出，共十次，losses数组共10个，固len(losses)=10
plt.plot(np.arange(len(losses))*100,losses, 'o-') 
plt.xlabel('epoch')
plt.ylabel('MSE')                                # 平均误差
plt.show()


```

损失值随迭代次数增加而递减：

<img src="E:\typora-user-images\image-20200520220256113.png" alt="image-20200520220256113" style="zoom:67%;" />

数据的可视化：

<img src="E:\typora-user-images\image-20200520220448028.png" alt="image-20200520220448028" style="zoom: 50%;" />





#### 2、调用pytorch内现成的函数，构建序列化的神经网络（2.1版本）

```python
# 直接调用内置函数
input_size = features.shape[1]
hidden_size = 10
output_size = 1
batch_size = 128
neu = torch.nn.Sequential(torch.nn.Linear(input_size, hidden_size),
                          torch.nn.Sigmoid(),
                          torch.nn.Linear(hidden_size, output_size))
cost = torch.nn.MSELoss()
optimizer = torch.optim.SGD(neu.parameters(), lr = 0.01)
losses = []
for i in range(1000):
    # 每128个样本点被划分为一个撮，在循环的时候一批一批地读取
    batch_loss = []
    # start和end分别是提取一个batch数据的起始和终止下标
    for start in range(0, len(X), batch_size):
        end = start + batch_size if start + batch_size < len(X) else len(X)
        xx = torch.tensor(X[start:end], dtype=torch.float, requires_grad=True)
        yy = torch.tensor(Y[start:end], dtype=torch.float, requires_grad=True)
        predict = neu(xx)
        loss = cost(predict, yy)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        batch_loss.append(loss.data.numpy())

    # 每隔100步输出一下损失值（loss）
    if i % 100 == 0:
        losses.append(np.mean(batch_loss))
        print(i, np.mean(batch_loss))

# 打印输出损失值
print(losses)
fig = plt.figure(figsize=(10, 7))
plt.plot(np.arange(len(losses)) * 100, losses, 'o-')
plt.xlabel('epoch')
plt.ylabel('MSE')
plt.show()
```

i, np.mean(batch_loss):

![image-20200603181655874](E:\typora-user-images\image-20200603181655874.png)

losses:

![image-20200602173017875](E:\typora-user-images\image-20200602173017875.png)



<img src="E:\typora-user-images\image-20200520225533927.png" alt="image-20200520225533927" style="zoom: 50%;" />



#### 3、对比两者损失函数图



```python
import time
tic=time.time()
toc=time.time()
print=('2.0\2.1版本： ' + str(toc-tic))   # 对比两个版本运行的时间
```

![image-20200601163724998](E:\typora-user-images\image-20200601163724998.png)

可以看出，调用内置函数，迭代速度更精确，是什么原理呢？

![image-20200605135303198](E:\typora-user-images\image-20200605135303198.png)

![image-20200605135714442](E:\typora-user-images\image-20200605135714442.png)

但两者速度运行速度差不多。

### 3.3 测试神经网络

测试神经网络，固然是通过测试集，输入调试好后的神经网络后，看预测值与实际值之间的差异。

test_targets内有三个“类”，这里先只关注’cnt‘类



```python
targets = test_targets['cnt']
targets = targets.values.reshape([len(targets), 1])
targets = targets.astype(float)   # 保证为实数

x = torch.tensor(test_features.values, dtype=torch.float, requires_grad=True)
y = torch.tensor(targets, dtype=torch.float, requires_grad=True)
print(x[:2])                      # 只输出x前两行数据
```

x[:2]:

<img src="E:\typora-user-images\image-20200521094933850.png" alt="image-20200521094933850" style="zoom:50%;" />

```python

predict = neu(x)
print(neu(x))
print(len(neu(x)))
predict = predict.data.numpy()      # 转换numpy
print((predict * std + mean)[:10])  # 归一化公式返回值，原本区间[-1,1]，变为原本范围。

# 这时候对比预测值与实际值，区别是横坐标要更改为日期

fig, ax = plt.subplots(figsize=(10, 7))  # ax为坐标系，下面会解释
ax.plot(predict * std + mean, label='Prediction', linestyle='--')  # 预测值用虚线表达
ax.plot(targets * std + mean, label='Data', linestyle='-')  # 原数据用实线表达
ax.legend()  # 图标上表明每条曲线的文字说明
ax.set_xlabel('Date-time')
ax.set_ylabel('Counts')


# 对x轴进行标注，注意这里dates天数，不是data。
dates = pd.to_datetime(rides.loc[test_data.index]['dteday'])
print(dates)
dates = dates.apply(lambda d: d.strftime('%b %d'))    # 3.5知识点汇总内第5个
print(dates)
ax.set_xticks(np.arange(len(dates))[12::24])     # 这里[12：：24]指的是数据从第12个开始，并以步长24前进读取。
_ = ax.set_xticklabels(dates[12::24], rotation=45)
plt.show()
```

`neu(x):`

![image-20200605142438663](E:\typora-user-images\image-20200605142438663.png)

`len(neu(x))：`     504，因为测试集的长度只有504.

​                              

两个dates（日期）之间的区别:

<img src="E:\typora-user-images\image-20200521201502036.png" alt="image-20200521201502036" style="zoom:50%;" />

<img src="E:\typora-user-images\image-20200521201132135.png" alt="image-20200521201132135" style="zoom: 67%;" />











#### 1、结果对比：

运行后有两个问题：

一是预测值不对：

![image-20200521152835786](E:\typora-user-images\image-20200521152835786.png)

二是这里纵坐标明显不对，明明返回了归一化数值，怎么还是1以内？

![image-20200521120752487](E:\typora-user-images\image-20200521120752487.png)





原因在于：未对 y 的均值，方差定义！

```python
mean,std =scaled_features['cnt']      # 这里方差与均值来自于cnt类内。从字典字典中直接提取。
print((predict * std + mean)[:10])
ax.plot(predict * std + mean, label='Prediction', linestyle='--')  # 预测值用虚线表达
ax.plot(targets * std + mean, label='Data', linestyle='-')  # 原数据用实线表达
```

更正后显示效果如下：

预测值：

![image-20200521153429397](E:\typora-user-images\image-20200521153429397.png)

 预测值与原数据可视化：

![image-20200521132340779](E:\typora-user-images\image-20200521132340779.png)



可以明细看出来，相比前面1.0版本的数据拟合程度，这个更加符合现实，拟合程度也更高。



### 3.4 诊断神经网络（剖析）

数据拟合后也显示了效果，也有偏差的地方。这里我们就看看是哪一些神经元使得预测相对较好，哪些神经元使得产生了偏差。

操作如下：

#### 1、先将部分偏差大的数据提取（原始数据）

```python
# 神经网络的诊断

# 先选出三天预测不准的日期，Dec 22, 23，24
# 将这三天的数据聚集到一起，存入subset和subtargets中
bool1 = rides['dteday'] == '2012-12-22'
bool2 = rides['dteday'] == '2012-12-23'
bool3 = rides['dteday'] == '2012-12-24'
print(bool1)
print(bool2)
print(bool3)
# tup原形tuple元组，元组与列表相似，元组内元素不可以修改，只可以连接合并
# zip()函数的作用，zip() 函数用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，下面会解释
bools = [any(tup) for tup in zip(bool1,bool2,bool3)]  # 读取每一个元组
print(bools)
print(rides[bools].index)
subset = test_features.loc[rides[bools].index]    
print(subset)
subtargets = test_targets.loc[rides[bools].index]
print(subtargets)
subtargets = subtargets['cnt']
print(subtargets)
subtargets = subtargets.values.reshape([len(subtargets),1]) # 转换矩阵
print(subtargets)
```

bool1:

<img src="E:\typora-user-images\image-20200522174701954.png" alt="image-20200522174701954" style="zoom: 67%;" />

bool2：

<img src="E:\typora-user-images\image-20200522174828776.png" alt="image-20200522174828776" style="zoom:67%;" />

bool3：

<img src="E:\typora-user-images\image-20200522174903110.png" alt="image-20200522174903110" style="zoom:67%;" />

bools：未全部现实，17379*3个

<img src="E:\typora-user-images\image-20200522175304017.png" alt="image-20200522175304017" style="zoom:150%;" />

rides[bools].index:

![image-20200606204340132](E:\typora-user-images\image-20200606204340132.png)

subset：

<img src="E:\typora-user-images\image-20200522175346527.png" alt="image-20200522175346527" style="zoom: 67%;" />



第一个subtargets：

![image-20200522175453523](E:\typora-user-images\image-20200522175453523.png)

第二个subtargets：

![image-20200522175601417](E:\typora-user-images\image-20200522175601417.png)

第三个subtargets：  71行，未全部显示。

![image-20200522175701118](E:\typora-user-images\image-20200522175701118.png)



#### 2、再提取各隐藏层内的输出数据（预测数据）

找出表现相对比较好的隐藏层

```python
# 定义了一个函数可以提取网络的权重信息，所有的网络参数信息全部存储在了neu的named_parameters集合中
def feature(X, net):
    # 只需提取超参数的数值，不需要求导
    X = torch.tensor(X, dtype=torch.float, requires_grad=False)  
    dic = dict(net.named_parameters())   # 提取出来这个集合
    weights = dic['0.weight']            # 可以按照层数.名称来索引集合中的相应参数值
    biases = dic['0.bias']               # 可以按照层数.名称来索引集合中的相应参数值
    # 隐含层的计算过程
    h = torch.sigmoid(X.mm(weights.t()) + biases.expand([len(X), len(biases)]))  
    return h                             # 返回输出层的计算


# 将这几天的数据输入到神经网络中，读取出隐含层神经元的激活数值，存入results中
results = feature(subset.values, neu).data.numpy()
print(results)
# 这些数据对应的预测值（输出层）
predict = neu(torch.tensor(subset.values, dtype=torch.float, requires_grad=True)).data.numpy()
# 将预测值还原成原始数据的数值范围
mean, std = scaled_features['cnt']
predict = predict * std + mean
subtargets = subtargets * std + mean
# 将所有的神经元激活水平画在同一张图上，蓝色的是模型预测的数值
fig, ax = plt.subplots(figsize=(8, 6))
ax.plot(results[:, :], '.:', alpha=0.3)  # alpha调节透明度
print(results[:, :])
ax.plot((predict - min(predict)) / (max(predict) - min(predict)), 'bs-', label='Prediction')  # 偏差比重
ax.plot((subtargets - min(predict)) / (max(predict) - min(predict)), 'ro-', label='Real')
ax.plot(results[:, 3], ':*', alpha=1, label='Neuro 4')
print(results[:, 3])

ax.set_xlim(right=len(predict))   # 定义x轴的长度
ax.legend()
plt.ylabel('Normalized Values')

dates = pd.to_datetime(rides.loc[subset.index]['dteday'])
dates = dates.apply(lambda d: d.strftime('%b %d'))
ax.set_xticks(np.arange(len(dates))[12::24])
_ = ax.set_xticklabels(dates[12::24], rotation=45)
plt.show()

# 找到了与峰值相应的神经元，把它到输入层的权重输出出来
dic = dict(neu.named_parameters())
weights = dic['0.weight'][3]
plt.plot(weights.data.numpy(), 'o-')
print(weights.data.numpy())
plt.xlabel('Input Neurons')
plt.ylabel('Weight')
plt.show()

# 将所有的神经元激活水平画在同一张图上，蓝色的是模型预测的数值
fig, ax = plt.subplots(figsize=(8, 6))
ax.plot(results[:, :], '.:', alpha=0.3)  # alpha调节透明度
ax.plot((predict - min(predict)) / (max(predict) - min(predict)), 'bs-', label='Prediction')  # 偏差比重
ax.plot((subtargets - min(predict)) / (max(predict) - min(predict)), 'ro-', label='Real')
ax.plot(results[:, 1], ':*', alpha=1, label='Neuro 2')
print(results[:, 1])

ax.set_xlim(right=len(predict))
ax.legend()
plt.ylabel('Normalized Values')

dates = pd.to_datetime(rides.loc[subset.index]['dteday'])
dates = dates.apply(lambda d: d.strftime('%b %d'))
ax.set_xticks(np.arange(len(dates))[12::24])
_ = ax.set_xticklabels(dates[12::24], rotation=45)  # _= 这里我猜测的是，前面设定了x轴上有几个点，这里就是设置点的名称
plt.show()

# 找到了与峰值相应的神经元，把它到输入层的权重输出出来
dic = dict(neu.named_parameters())
weights = dic['0.weight'][1]
plt.plot(weights.data.numpy(), 'o-')
print(weights.data.numpy())
plt.xlabel('Input Neurons')
plt.ylabel('Weight')
plt.show()
```

result，result[: , :]：

<img src="E:\typora-user-images\image-20200522203159517.png" alt="image-20200522203159517" style="zoom:67%;" />



result[:,3]，result数据中第四列

<img src="E:\typora-user-images\image-20200522203317475.png" alt="image-20200522203317475" style="zoom:67%;" />

对比各个权重层：

<img src="E:\typora-user-images\image-20200522203125081.png" alt="image-20200522203125081" style="zoom:67%;" />



<img src="E:\typora-user-images\image-20200522203658124.png" alt="image-20200522203658124" style="zoom:50%;" />

第四个隐藏层对提高预测精确度起到更高的作用。



而有上表result中看出，第二个隐藏层效果不明显，我们调出结果来看看：

<img src="E:\typora-user-images\image-20200522204856233.png" alt="image-20200522204856233" style="zoom:50%;" />

<img src="E:\typora-user-images\image-20200522204932092.png" alt="image-20200522204932092" style="zoom:67%;" />

#### 3、分析图表

![image-20200522205733215](E:\typora-user-images\image-20200522205733215.png)



两者权重对比，在西方，12月22日与23日正好是周末，24日正好是圣诞节平安夜。理论上是在早晨用车人数少，中午用车人数多。前者第四层隐藏层权重会负值抑制增长，中午12点为正值，促进数值。相反，第二层隐藏层的数据会在早晨促进数值，中午抑制人数。

事实上还需要考虑很多因素，比如节假日，是否下雪，都会影响输出。





```python
weights = dic['0.weight']
print(weights)
biases = dic['0.bias']
print(biases)
```

这里为读取隐藏层每个神经元输入的权重值（56 * 10）：

![image-20200606221122339](E:\typora-user-images\image-20200606221122339.png)

偏差：

![image-20200606222327786](E:\typora-user-images\image-20200606222327786.png)



### 3.5 知识点汇总

#### 1、`pd.concat`的定义：

`pd.concat`是pandas内一个函数工具，定义如下：

```python
def concat(
    objs,                    # objects 对象，需要连接的数据对象，表现形势为[x,y]
    axis=0,                  # 0为水平方向，1为垂直方向
    join="outer",            # 两个有索引数据合并，“outer”是全部合并，“inner”只取重合部分
    join_axes=None,          # 传入是否需要保留index
    ignore_index=False,      # 忽略需要连接的frame本身的索引。当原本的索引没有特别意义的时候可以使用
    keys=None,               
    levels=None,
    names=None,
    verify_integrity=False,
    sort=None,
    copy=True,
):
    
    
    # 源代码中
    rides = pd.concat([rides, dummies], axis=1)
```

#### 2、`plt.subplots`的定义：

```python
fig, ax = plt.subplots(figsize = (a, b))

def subplots(nrows=1, 
             ncols=1, 
             sharex=False, 
             sharey=False, 
             squeeze=True,
             subplot_kw=None, 
             gridspec_kw=None, 
             **fig_kw):         # 调用其他关键字参数传递给figure()调用，例如figsize（10，7）
```

这里fig为Figure（绘图窗口）；ax是axis(坐标系)代表绘图窗口上的坐标系，一般会继续对ax进行操作：

```python
ax.plot(predict * std + mean, label='Prediction', linestyle='--')   # 预测值用虚线表达
ax.plot(targets * std + mean, label='Data', linestyle='-')          # 原数据用实线表达
ax.legend()                             # lengend有图例的意思，图标上表明每条曲线的文字说明
ax.set_xlabel('Date-time')              # x轴名称
ax.set_ylabel('Counts')                 # y轴名称
```





#### 3、`data.loc` 与`data.iloc`的定义以及之间的区别：

![image-20200521164942224](E:\typora-user-images\image-20200521164942224.png)

.loc指的是location，以columns（列名）和index（行名）作为参数。

.iloc指的是index location，以二维矩阵的位置指标作为参数（即0，1，2......）

```python
# 此代码中loc的含义：
data.loc[:, each]   # loc[:,名称]，所有名称每列的所有数据


data=DataFrame(np.arange(16).reshape(4,4),index=list("ABCD"),columns=list("wxyz"))
print(data)
#    w   x   y   z
#A   0   1   2   3
#B   4   5   6   7
#C   8   9  10  11
#D  12  13  14  15

print(data.loc[:,"w"])       #(=print(data["w"]))
#A     0
#B     4
#C     8
#D    12
#Name: w, dtype: int32

print(data.loc[:,["w","y"]])
#    w   y
#A   0   2
#B   4   6
#C   8  10
#D  12  14

```



#### 4、`.to_datetime()` 的定义：

```python
def to_datetime(                       # 专门转化时间的函数
    arg,
    errors="raise",
    dayfirst=False,
    yearfirst=False,
    utc=None,
    box=True,
    format=None,
    exact=True,
    unit=None,
    infer_datetime_format=False,
    origin="unix",
    cache=True,
):
```

#### 5、`dates = dates.apply(lambda d: d.strftime('%b %d'))`

```python
dates = dates.apply(lambda d: d.strftime('%b %d'))

#lambda d:d 是将传递过来的参数，按value排序,d:d只是名称，变成sss:sss也不影响输出。

#.strftime() 表示是直接读取字符串时间，转化格式%来决定
    %y 两位数的年份表示（00-99）
    %Y 四位数的年份表示（000-9999）
    %m 月份（01-12）
    %d 月内中的一天（0-31）
    %H 24小时制小时数（0-23）
    %I 12小时制小时数（01-12）
    %M 分钟数（00=59）
    %S 秒（00-59）
    %a 本地简化星期名称
    %A 本地完整星期名称
    %b 本地简化的月份名称（英文缩写开头）
    %B 本地完整的月份名称
    %c 本地相应的日期表示和时间表示
    %j 年内的一天（001-366）
    %p 本地A.M.或P.M.的等价符
    %U 一年中的星期数（00-53）星期天为星期的开始
    %w 星期（0-6），星期天为星期的开始
    %W 一年中的星期数（00-53）星期一为星期的开始
    %x 本地相应的日期表示
    %X 本地相应的时间表示
    %Z 当前时区的名称
    %% %号本身
    
# 所以d.strftime('%b %d')，  %b缩写英文，%d月内的一天（0-31）

```

#### 6、布尔型数组

true 与 false ，数组内符合的元素输出为true，不符为false。



#### 7、内置函数运算速度检测

```python
import numpy as np
a = np.array([1,2,3,4])
print(a)
import time
a = np.random.rand(1000000)
b = np.random.rand(1000000)
print(a)

tic = time.time()
c = np.dot(a,b)   # 内置函数dot()
toc = time.time()

print(c)
print("Vectorization version: " + str(1000*(toc-tic)) + "ms")

c = 0
tic = time.time()
for i in range(1000000): # 循环
    c += a[i]*b[i]
toc = time.time()

print(c)
print("For loop: "  + str(1000*(toc-tic)) + "ms")
```

![image-20200605133721599](E:\typora-user-images\image-20200605133721599.png)